# -*- coding: utf-8 -*-
"""Admin Dashboard Module

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v2lo141LBE6Pf0rWSM673nvuhu6zfjX0
"""

import pandas as pd
import json
import logging
import os
from datetime import datetime
import ast
import re

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Get the directory where this module lives
CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))


# Helper: try multiple candidate locations for the log files so the dashboard
# works regardless of current working directory or how Streamlit was launched.
def _resolve_log_file(filename: str) -> str:
    """Return an existing path for filename by trying several common locations.

    Order of attempts:
    1) <repo_root>/streamlit_app/<filename>
    2) <cwd>/streamlit_app/<filename>
    3) next to this module (backend/<filename>)
    4) as provided (fallback)
    """
    candidates = []

    # Determine the most likely project root: parent of the backend folder
    project_root = os.path.abspath(os.path.join(CURRENT_FILE_DIR, '..'))

    # Candidate 1: <project_root>/streamlit_app/<filename>
    candidates.append(os.path.join(project_root, 'streamlit_app', filename))

    # Candidate 2: current working dir + streamlit_app
    candidates.append(os.path.join(os.getcwd(), 'streamlit_app', filename))

    # Candidate 3: <project_root>/<filename> (in case files live at repo root)
    candidates.append(os.path.join(project_root, filename))

    # Candidate 4: next to this module (backend/<filename>)
    candidates.append(os.path.join(CURRENT_FILE_DIR, filename))

    # Normalize and try each candidate
    tried = []
    for path in candidates:
        p = os.path.normpath(os.path.abspath(path))
        tried.append(p)
        if os.path.exists(p):
            logger.info(f"Resolved log file for '{filename}' -> {p}")
            return p

    # As a last resort, also try the explicit streamlit_app path that the UI shows
    explicit = os.path.normpath(os.path.abspath(os.path.join(project_root, 'streamlit_app', filename)))
    tried.append(explicit)
    if os.path.exists(explicit):
        logger.info(f"Resolved log file for '{filename}' -> {explicit}")
        return explicit

    logger.warning(f"Could not find existing file for '{filename}'. Tried: {tried}")
    # Return the most likely path (project_root/streamlit_app/<filename>) as a fallback
    return explicit


# Define file paths by resolving candidates
FEEDBACK_FILE = _resolve_log_file('feedback_log.json')
HISTORY_FILE = _resolve_log_file('user_history.json')

def _load_data(filename: str) -> pd.DataFrame:
    """Helper function to load a JSON log file into a DataFrame."""
    logger.info(f"Loading data from {filename}")
    logger.info(f"File exists: {os.path.exists(filename)}")
    try:
        # Read the JSON file first
        with open(filename, 'r') as f:
            data = json.load(f)
        
        # Convert the JSON array to DataFrame
        if not isinstance(data, list):
            logger.warning(f"{filename} does not contain a JSON array.")
            return pd.DataFrame()
            
        if not data:  # Empty list
            logger.warning(f"{filename} contains an empty array.")
            return pd.DataFrame()
            
        # Convert the JSON array to DataFrame with explicit dtypes
        df = pd.DataFrame.from_records(data)
        
        # Convert timestamp strings to datetime objects
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
        return df
    except FileNotFoundError:
        logger.warning(f"File not found: {filename}. Returning empty DataFrame.")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        logger.warning(f"Could not parse {filename} (it might be empty or malformed): {e}")
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"An unexpected error occurred loading {filename}: {e}")
        return pd.DataFrame()

def get_dashboard_stats() -> dict:
    """
    Reads from log files and computes dashboard statistics.

    Returns:
        A dictionary containing:
        - average_rating: Mean of all ratings (float)
        - total_feedback: Total number of feedback entries (int)
        - top_queries: Dict of top 5 trending queries and their counts
        - language_stats: Dict of language usage and their counts
        - total_queries: Total number of queries processed (int)
    """
    try:
        feedback_df = _load_data(FEEDBACK_FILE)
        history_df = _load_data(HISTORY_FILE)

        stats = {
            "average_rating": 0.0,
            "total_feedback": 0,
            "top_queries": {},
            "language_stats": {},
            "total_queries": 0
        }

        # Add a code_quality placeholder to return derived heuristics
        stats['code_quality'] = {
            'execution_success_pct': 0.0,
            'execution_failure_count': 0,
            'syntax': {
                'python_checked': 0,
                'python_syntax_ok': 0,
                'pct_ok': 0.0,
            },
            'runtime': {
                'Good': 0,
                'Average': 0,
                'Poor': 0,
            }
        }

        # 1. Average Feedback Rating
        if not feedback_df.empty and 'rating' in feedback_df.columns:
            stats['average_rating'] = float(round(feedback_df['rating'].mean(), 2))
            stats['total_feedback'] = int(feedback_df['rating'].count())

        # 2. Top 5 Trending Queries
        if not history_df.empty and 'query' in history_df.columns:
            # Standardize queries for better grouping
            queries = history_df['query'].str.lower().str.strip()
            stats['top_queries'] = {
                str(k): int(v) 
                for k, v in queries.value_counts().nlargest(5).items()
            }
            stats['total_queries'] = int(history_df.shape[0])

            # 4. Code quality heuristics (derived from history entries)
            try:
                total = history_df.shape[0]
                failures = 0
                py_checked = 0
                py_ok = 0
                runtime_counts = {'Good': 0, 'Average': 0, 'Poor': 0}

                for idx, row in history_df.iterrows():
                    code = str(row.get('generated_code', '') or '')
                    lang = str(row.get('language', '') or '').strip().lower()

                    # Execution success heuristic: mark as failure if the generated
                    # code looks like an error/traceback or starts with 'Error:'
                    if re.search(r"\b(Error:|Traceback|Exception|SyntaxError)\b", code, re.IGNORECASE):
                        failures += 1

                    # Syntax correctness: only attempt for Python snippets
                    if lang == 'python':
                        py_checked += 1
                        try:
                            # Use ast.parse to detect syntax errors without executing
                            ast.parse(code)
                            py_ok += 1
                        except Exception:
                            # syntax error detected
                            pass

                    # Runtime performance heuristic: naive proxy using code size
                    # Shorter snippets are considered likely 'Good', medium 'Average', long 'Poor'
                    lines = code.count('\n') + 1 if code else 0
                    if lines <= 20:
                        runtime_counts['Good'] += 1
                    elif lines <= 100:
                        runtime_counts['Average'] += 1
                    else:
                        runtime_counts['Poor'] += 1

                # Populate stats
                stats['code_quality']['execution_failure_count'] = int(failures)
                stats['code_quality']['execution_success_pct'] = float(round((1 - (failures / total)) * 100, 2)) if total > 0 else 0.0
                stats['code_quality']['syntax']['python_checked'] = int(py_checked)
                stats['code_quality']['syntax']['python_syntax_ok'] = int(py_ok)
                stats['code_quality']['syntax']['pct_ok'] = float(round((py_ok / py_checked) * 100, 2)) if py_checked > 0 else 0.0
                stats['code_quality']['runtime'] = runtime_counts
            except Exception as e:
                logger.warning(f"Failed to compute code quality heuristics: {e}")

        # 3. Language Usage Stats
        if not history_df.empty and 'language' in history_df.columns:
            # Normalize language names (e.g., 'python' -> 'Python'), fill missing
            langs = history_df['language'].fillna('Unknown').astype(str).str.strip()
            langs = langs.replace({'': 'Unknown'})
            langs = langs.str.title()
            stats['language_stats'] = {
                str(k): int(v)
                for k, v in langs.value_counts().items()
            }

        logger.info("Successfully computed dashboard stats.")
        return stats
    except Exception as e:
        logger.error(f"Error computing dashboard stats: {e}")
        return {
            "average_rating": 0.0,
            "total_feedback": 0,
            "top_queries": {},
            "language_stats": {},
            "total_queries": 0
        }

if __name__ == "__main__":
    # Example usage
    # Ensure the .json files exist from running the other scripts first
    print("--- Testing Admin Dashboard ---")
    dashboard_data = get_dashboard_stats()

    import pprint
    pp = pprint.PrettyPrinter(indent=2)
    pp.pprint(dashboard_data)